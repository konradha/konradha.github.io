<!doctype html><html class="not-ready lg:text-base" style=--bg:#f8f5d7 lang=en dir=ltr><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Affinity - א</title><meta name=theme-color><meta name=description content="You have some nested loop and you found
a strategy to parallelize it. You don&rsquo;t introduce false sharing, race conditions,
anything you don&rsquo;t want. It looks somewhat like this when using OpenMP:
# pragma omp parallel for // collapse, ...
for (size_t i = 0; i < nx; i += kx)
        // do work
Do you let your OS or your OpenMP implementation decide where these threads are sitting?
Luckily, there are several tools that can help you explore these choices."><meta name=author content="א"><link rel="preload stylesheet" as=style href=https://konradha.com/main.min.css><link rel=preload as=image href=https://konradha.com/theme.png><script defer src=https://konradha.com/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js async></script><link rel=icon href=https://konradha.com/favicon.ico><link rel=apple-touch-icon href=https://konradha.com/apple-touch-icon.png><meta name=generator content="Hugo 0.147.6"><meta itemprop=name content="Affinity"><meta itemprop=description content="You have some nested loop and you found a strategy to parallelize it. You don’t introduce false sharing, race conditions, anything you don’t want. It looks somewhat like this when using OpenMP:
# pragma omp parallel for // collapse, ... for (size_t i = 0; i < nx; i += kx) // do work Do you let your OS or your OpenMP implementation decide where these threads are sitting?
Luckily, there are several tools that can help you explore these choices."><meta itemprop=datePublished content="2024-01-03T17:49:50+01:00"><meta itemprop=dateModified content="2024-01-03T17:49:50+01:00"><meta itemprop=wordCount content="302"><meta property="og:url" content="https://konradha.com/posts/affinity/"><meta property="og:site_name" content="א"><meta property="og:title" content="Affinity"><meta property="og:description" content="You have some nested loop and you found a strategy to parallelize it. You don’t introduce false sharing, race conditions, anything you don’t want. It looks somewhat like this when using OpenMP:
# pragma omp parallel for // collapse, ... for (size_t i = 0; i < nx; i += kx) // do work Do you let your OS or your OpenMP implementation decide where these threads are sitting?
Luckily, there are several tools that can help you explore these choices."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-03T17:49:50+01:00"><meta property="article:modified_time" content="2024-01-03T17:49:50+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Affinity"><meta name=twitter:description content="You have some nested loop and you found a strategy to parallelize it. You don’t introduce false sharing, race conditions, anything you don’t want. It looks somewhat like this when using OpenMP:
# pragma omp parallel for // collapse, ... for (size_t i = 0; i < nx; i += kx) // do work Do you let your OS or your OpenMP implementation decide where these threads are sitting?
Luckily, there are several tools that can help you explore these choices."><link rel=canonical href=https://konradha.com/posts/affinity/></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center"><div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center"><a class="-translate-y-[1px] text-2xl font-medium" href=https://konradha.com/>א</a><div class="btn-dark text-[0] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#f8f5d7".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100vh-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"><article><header class=mb-14><h1 class="!my-0 pb-2.5">Affinity</h1><div class="text-xs antialiased opacity-60"><time>Jan 3, 2024</time></div></header><section><p>You have some nested loop and you found
a strategy to parallelize it. You don&rsquo;t introduce false sharing, race conditions,
anything you don&rsquo;t want. It looks somewhat like this when using OpenMP:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e># pragma omp parallel for </span><span style=color:#75715e>// collapse, ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span> (size_t i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> nx; i <span style=color:#f92672>+=</span> kx)
</span></span><span style=display:flex><span>        <span style=color:#75715e>// do work
</span></span></span></code></pre></div><p>Do you let your OS or your OpenMP implementation decide where these threads are sitting?</p><p>Luckily, there are several tools that can help you explore these choices.</p><p>An example: I&rsquo;m running on some Ryzen chip. <code>lstopo</code> is a nice command giving you some insight into
how you can allocate your resources.</p><p>It looks like this on my side:</p><img src=/topo.png><p>As we can see there are 8 physical cores available to me.</p><p>Setting the affinity to a <em>thread</em> is now done with</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>GOMP_CPU_AFFINITY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0,2,4,6,8,10,12,14&#34;</span>
</span></span></code></pre></div><p>Why did I do it like this here? My specific loop makes use of independent data for every thread.
You don&rsquo;t want threads sitting on the same island to hammer your bus as this will reduce performance.
There are possibly applications where using</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>GOMP_CPU_AFFINITY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0,1,2,3,4,5,6,7&#34;</span>
</span></span></code></pre></div><p>is practical &ndash; you will have to benchmark this for your specific case. Notably, $GOMP_CPU_AFFINITY
will <em>not</em> set the number of threads used per se.</p><p>Having understood this setup, it&rsquo;s easy (RTFM) to distribute this work onto several
nodes if you&rsquo;ve got MPI enabled. You&rsquo;d want to rewrite this as a loop when on a cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mpirun -np <span style=color:#ae81ff>1</span> -x OMP_NUM_THREADS<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span> -x GOMP_CPU_AFFINITY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0,2,4,6&#34;</span> ./to_mpi $1 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        : -np <span style=color:#ae81ff>1</span> -x OMP_NUM_THREADS<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span> -x GOMP_CPU_AFFINITY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;8,10,12,14&#34;</span> ./to_mpi $1
</span></span></code></pre></div><p>If I&rsquo;ve done my homework and haven&rsquo;t left any single-core and OpenMP performance on the table, this should come close
to what&rsquo;s possible on my machine. Of course, you now have to watch out for communication overhead and
load imbalance. Maybe I&rsquo;ll explore this at a later point.</p></section><nav class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"><a class="ltr:pr-3 rtl:pl-3" href=https://konradha.com/posts/sliced_traversal/><span class="ltr:mr-1.5 rtl:ml-1.5">←</span><span>Sliced traversals</span></a>
<a class="ltr:ml-auto rtl:mr-auto justify-end pl-3" href=https://konradha.com/posts/pinns/><span>Solving PDEs using ✨Machine Learning✨</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a></nav></article></main><footer class="mx-auto flex h-[4.5rem] max-w-[--w] items-center px-8 text-xs uppercase tracking-wider opacity-60"><div class=mr-auto>&copy; 2025
<a class=link href=https://konradha.com/>א</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>powered by hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>hugo-paper</a></footer></body></html>